% vim : set tabstop=4 shiftwidth=4 expandtab:

\documentclass[varwidth=15cm, border=.5cm]{standalone}
\usepackage{amsmath, amsfonts, amsthm, hyperref, mdframed, thmtools, enumitem}

\mdfsetup{linewidth=1.5pt, topline=false, rightline=false, bottomline=false, leftline=true}
\declaretheoremstyle[ notebraces={}{}, headpunct=, headformat=\NAME{} --\NOTE, postheadhook=\leavevmode\begin{mdframed}, prefoothook=\end{mdframed}, ]{default}
\declaretheorem[ name=Satz, style=default,]{theorem}
\declaretheorem[ name=Definition, style=default,]{definition}
\declaretheorem[ name=Remark, style=default,]{remark}
\declaretheorem[ name=Proposition, style=default,]{proposition}
\declaretheorem[ name=Beispiel, style=default,]{example}

\DeclareMathOperator{\prox}{prox}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator{\id}{Id}
\DeclareMathOperator{\jacobian}{D}
\DeclareMathOperator{\proj}{\Pi}
\DeclareMathOperator{\indicator}{I}
\DeclareMathOperator{\diff}{d}
\DeclareMathOperator{\dist}{dist}
\DeclareMathOperator{\domain}{dom}


\newcommand*\from{\colon}
\newcommand{\innerp}[2]{\left\langle #1 \vert #2 \right\rangle}
\newcommand{\optimal}[1]{{#1^{\scriptscriptstyle\bullet}}}
\renewcommand*{\emptyset}{\text{\O}}

\begin{document}

\begin{theorem}[label=pb8y7i3e, name=Boundedness of operators]
	All odd numbers are prime. 

	\begin{theorem}[A side note]
		Blub
	\end{theorem}
\end{theorem}

\begin{definition}[label=f6izn8iw, name=Proximal Operator]
	The proximal operator (also see resolvant for CCP case) is given by 

	\[
        \prox_{\lambda f}(x) = \argmin_y \{ \Theta(y; x) = \lambda f(y) +
        \frac{1}{2}\lVert y - x\rVert_2^2\}
	\]

    \begin{theorem}[label=78req5r7, name=Convergence with Lyapunov Analysis]
        Let \( f\in\mathcal{F}_{0,\infty} \). For any \( k\in\mathbb{N}, A_k, \lambda_k > 0\) and any \( x_k \), the inequality
        \begin{alignat*}{6}
            &A_{k+1}&&(f(x_{k+1}) &&- f(x^\star)) &&+ &&\frac{1}{2}\lVert x_{k+1} &&- x_\star\rVert^2_2  \\
            \leq &A_k&&(f(x_k)   &&- f(x^\star)) &&+ &&\frac{1}{2}\lVert x_k   &&- x^\star\rVert_2^2
        \end{alignat*}

        holds for iteration \( x_{k+1} = \prox_{\lambda_kf}(x_k) \) and number \(A_{k+1}= A_k + \lambda_k\).
    \end{theorem}

    \begin{remark}[label=hnns6j86, name=Computation complexity]
        Proximal operations are in general expensive, sometimes as expensive as
        minimizing the function itself. There are however many instances of
        function \( f \) for which an analytic solution exists. For composite
        problems, those parts are isolated and solved separately by a
        conceptional proximal operator.
    \end{remark}
\end{definition}

\begin{definition}[label=m2qlq7ne, name=Cocoercive Operators]
	An operator \( \mathcal{T} \) is \textit{\( \mu \)-stronly monotone} or \textit{\( \mu \)-cocoercive}  if there exists 
	a \( \beta > 0 \), for which the following inequality holds globally
	\[
		\innerp{x - y}{\mathcal{T}x - \mathcal{T}y} \geq \beta\lVert\mathcal{T}x - \mathcal{T}y\rVert^2 \quad \forall (x, y).
	\]
	\begin{proposition}[label=wk4xp5i4, name=Cocoerciveness of nonexpansive operators]
		Let \( \mathcal{T} \) be a proper operator, then (\( \mathcal{T} \) is non-expansive) 
		\( \iff \) (\( \id - \mathcal{T} \) is \( 1/2\)-cocoercive).
	\end{proposition}

	\begin{proposition}[label=fgebss0l, name=Sum of cocoercive operators
		under transformation]
		Let \( \mathcal{T}_i \) a family of \( \beta_i \)-cocoercive operators with \( L_i \in \mathcal{B}(\mathcal{H}, \mathcal{K}_i) \)
		and \( \beta_i > 0 \). Set

		\[
			T = \sum_i L_i^\star\mathcal{T}_iL_i \quad \beta^{-1} = \sum_i \frac{\lVert L_i\rVert^2}{\beta_i}
		\]

		then \( \mathcal{T} \) is \( \beta \)-cocoercive.
	\end{proposition}

	%\begin{remark}[label=xno_2i29, name=Connection to Lipschitz continuous]
	%\end{remark}
\end{definition}

\begin{definition}[label=5nalj3hx, name=Lipschitz Regularity]
	For \( L > 0 \), we say that a mapping \( \mathcal T\from\mathbb R^n\to\mathbb R^m \) is L-Lipschitz if globally
	\[
		\lVert \mathcal T(x) - \mathcal T(y) \rVert \leq L\lVert x - y\rVert \qquad \forall x,y\in\mathbb R^n.
	\]
	If a mapping is Lipschitz, it is a continuous mapping because for every
	\( \lVert x - y \rVert < \delta \) exists \( \epsilon < L \delta \). The composition of \( \mathcal T_1 \) and \( \mathcal T_2 \), 
	\( \mathcal T_1 \circ \mathcal T_2 \), is \( L_1L_2 \)-Lipschitz (\textit{hint} apply Lipschitz inequality twice).
	The sum of two mappings, \( \alpha_1\mathcal T_1 + \alpha_2\mathcal T_2 \) is \((|\alpha_1|L_1 + |\alpha_2|L_2)\)-Lipschitz.

	\begin{example}[label=17vzrkyq, name=Affine Function]
		An affine function \(F(x) = Ax + b\) has Lipschitz constant \(L=\lVert A\rVert_2\), 
		the spectral norm or maximum singular value of \(A\).
	\end{example}

	\begin{example}[label=jydhwyqa, name=Differentiable Function]
		Let \( \mathcal T\from\mathcal R^n\to\mathcal R^n\) be a differentiable function, then 
		\[
			\text{L-Lipschitz} \quad \leftrightarrow \quad \lVert\jacobian f(x)\rVert_2 \leq L
		\]

		\begin{tabular}{rl}
			For a proof & (\( \implies \)) bound definition of differentials \\
				    & (\( \impliedby \)) apply mean value
				    theorem and Cauchy-Schwartz inequality to \\
				    &\quad\(g(t) = (\mathcal Tx - \mathcal Ty)^T\mathcal T(tx + (1-t) y) \)\\
				    &\quad(with \(\lVert\mathcal Tx - \mathcal Ty\rVert^2_2 = g(1) - g(0)\))
		\end{tabular}
	\end{example}

	\begin{example}[label=5pxh2ufj, name=Projections]
		The projection of \(x\) onto a non-empty closed convex set \(
		\mathcal C\) is defined as 
		\[
			\proj_\mathcal{C}(z) = \argmin_{x\in\mathcal C}\lVert z
			-x\rVert_2 = \prox_{\indicator(x\in\mathcal C)}(z)
		\]

		and a \hyperref[2s6tfa1j]{non-expansive} operator with unique
		closest point in \( \mathcal C\).

		For a proof see that the closest projection of \(x\) is a
		fixed-point \(\proj_{\mathcal C}\optimal{x} = \optimal{x}\) and
		the differential \( \diff_\optimal{x}\proj_{\mathcal C}x =
		\diff_\optimal{x}(x - \dist_{\mathcal C}x) = (\proj_{\mathcal C}x
		- \optimal{x})\diff\optimal{x} \). Apply the optimality
		condition 

		\begin{alignat*}{2}
			(\jacobian\proj_{\mathcal C})(\optimal{x})^T&(y - \optimal{x}) &&\geq 0 \\
			(\proj_{\mathcal C}u - u)^T&(y - \proj_{\mathcal C}(u)) &&\geq 0
		\end{alignat*}
		at two points \(x,y\in\mathbb R^n\). Adding both, apply
		Cauchy-Schwartz inequality to conclude
		\[
			\lVert\proj_{\mathcal C}x - \proj_{\mathcal C}y\rVert_2 \leq \rVert x - y\rVert_2.
		\]
		
	\end{example}

	\begin{remark}[label=2s6tfa1j, name=Nonexpansive and Contractive Mappings]
		A mapping is called nonexpansive for \( L \leq 1 \), contractive
		for \( L < 1 \).
	\end{remark}
\end{definition}

\begin{definition}[label=3rjrllrr, name=Strong Convexity Regularity]
	For \(\mu > 0\), we say that a mapping \( f\from\mathbb
	R^n\to\mathbb R^m \) is strongly convex if one of the following
	equivalent conditions hold \(\forall x,y\in\mathbb R^n\)

	\begin{enumerate}[label=\roman*\quad]
		\item \(f(y) - f(x) \geq \nabla f(x)^T(y-x) + \frac{\mu}{2}\lVert y - x\rVert^2\)
		\item \(g(x) = f(x) - \frac{\mu}{2}\lVert y-x\rVert^2_2\) is convex 
		\item \((\nabla f(y) - \nabla f(x))^T(y-x)\geq \mu\lVert x-y\rVert^2\)
		\item \(f(\alpha x+ (1-\alpha) y) \le \alpha f(x) + (1-\alpha) f(y) - \frac{\alpha (1-\alpha)\mu}{2}\Vert x-y\rVert^2,~\alpha \in [0,1].\)
	\end{enumerate}

	Strong convexity regularity implies that the function has a unique
	minimizer as the gradient difference of two points is bounded below and
	therefore can't vanish.

	\begin{remark}[label=dj4thzqo, name=Implications of Strong Convexity]
		The following conditions are implied by \(\mu>0\) strong
		convexity of a function $f$

		\begin{enumerate}[label=\roman*\quad,ref=(\roman*)]
			\item \label{dj4thzqo:pl} \(\frac{1}{2}\lVert\nabla f(x)\rVert^2\ge \mu (f(x)-f^*),~\forall x.\) 
			\item \(\lVert\nabla f(x) - \nabla f(y)\rVert \ge \mu \lVert x-y\rVert\)
			\item \(f(y)\le f(x)+\nabla f(x)^T(y-x)+\frac{1}{2\mu}\lVert\nabla f(y)- \nabla f(x)\rVert^2\)
			\item \((\nabla f(x) - \nabla f(y)^T(x-y) \le \frac{1}{\mu} \lVert\nabla f(x)-\nabla f(y)\rVert^2\)
		\end{enumerate}

		The condition \ref{dj4thzqo:pl} is also called the 
		Polyak-Lojasiewicz (PL) inequality. 
	\end{remark}

	\begin{remark}[label=_7nd1yv2, name=Strong Monotonicity of Subdifferentials]
		If the subdifferential of a convex mapping \(\partial\mathcal
		T\) is \hyperref[1_xd5vw5]{m-strongly} monotone, then the mapping 
		\(\mathcal T\) is m strong convex.
	\end{remark}

	\begin{remark}[label=4nciih04, name=Strong Convexity in Practice]
		For a strongly-convex, Lipschitz continuous function Gradient
		Descent converges in linear-time. In practice however, many
		applications (e.g., least square, logistic regression) do not
		fulfill strong convexity regularity. If they are only convex,
		then gradient descent can only be attested with sub-linear
		rate.

		This leads to weaker conditions, with which linear rate can
		still be attained, and are applicable to least square, logistic
		regression.
	\end{remark}
\end{definition}

\begin{definition}[label=xt9s0uma, name=Polyak-Lojasiewicz Regularity]
	For \(\mu > 0\) a mapping is Polyak-Lojasiewicz (PL) regular if the following 
	inequality holds
	\[
		\frac{1}{2\mu}\lVert v\rVert^2 \geq \mathcal T u - \mathcal T\optimal{u} \qquad \forall u\in\domain{\mathcal T}, v \in \partial\mathcal T(u).
	\]
	The condition requires that the gradient grows larger than a linear
	function when we move away from the optimal function value. 

	\begin{example}[label=ckhagcj4, name=Example for a quadratic function]
		Set \(f(x) = x^TAx, x\geq0\), we have from PL that,
		\(\lVert A^Tx\rVert^2 \geq 2\mu x^TAx\), and hence bounding with
		the maximum/minimum singular-value (assuming \(A\) is symmetric)
		\[
			\sigma_\text{max}(A)^2 \geq 2\mu\sigma_\text{min}(A)
		\]
		from which we can find a minimal upper bound for \(\mu\).
	\end{example}

	\begin{theorem}[label=zs9zsqoh, name=Convergence of Gradient Descent]
		Let \(f\) be L-Lipschitz continuous gradient, be PL regular and
		has a non-empty solution set. Then the gradient method with a
		step-size of \(1/L\)
		\[
			x_{k+1}=x_k-\frac{1}{L}\nabla f(x_k),
		\]
		has a global convergence rate depending on the function condition
		number \(\kappa = L/\mu\)
		\[
			f(x_k) - \optimal{f}\leq\left(\frac{\kappa-1}{\kappa}\right)^k(f(x_0) - \optimal{f}).
		\]

		For a proof substitute the forward step
		\(x_{k+1}-x_k=-\alpha\nabla f(x_k)\) into the Lipschitz
		continuous gradient conditions to upper-bound the gradient.
		Combine with PL inequality
		\[
			f(x_{k+1})-f(x_k) \leq -\frac{\mu}{L}(f(x_k) - \optimal{f})
		\]
		Reordering and applying recursivly until \(x\to x_0\) gives
		convergence inequality.
	\end{theorem}
	\begin{example}[label=jab2zae3, name=Strongly-convex composed with linear]
		Let \(f = g(Ax + b)\) be a function composed of strongly-convex 
		function \(g\) and some matrix \(A\). This has PL regularity and
		frequently arises in machine learning tasks, such as
		least-square or logistic regression.
	\end{example}
\end{definition}

\begin{remark}[label=9wm37o_t, name=Relationship between optimality bounds]
	Several lower bounds on the growth of a function give rise to
	convergence theorems. With the condition \(\mu>0\) and \(f(\optimal{x}) = 
	\optimal{f}\) we have the relation
	\begin{alignat}{3}
		&\text{SC}\to\text{ESC}\to\text{WSC}\to&\text{RSI}\to\text{EB}\equiv\text{PL}\to\text{QC} \\
		\text{for } f \text{ convex}~&&\text{RSI}\equiv\text{EB}\equiv\text{PL}\equiv\text{QC}.
	\end{alignat}

	\begin{enumerate}
		\item[SC --] Strong Convexity: \(f(y) \geq f(x) + \innerp{\nabla f(x)}{y-x} + \frac{\mu}{2}\lVert y-x\rVert^2\)
	\end{enumerate}
\end{remark}

\begin{definition}[label=1_xd5vw5, name=Monotone Operators and Coercivity]
	An operator \(\mathcal T\) on \(\mathbb R^n\) is called \textit{monotone} if it satisfies
	\[
		\innerp{u-v}{x-y} \geq 0\qquad\forall(x,u), (y,v)\in\mathcal T.
	\]
	Furthermore it is said to be \textit{stronly} monotone or \textit{coercive} with
	parameter \( m > 0\) if it holds
	\[
		\innerp{\mathcal T x- \mathcal T y}{x-y}\geq m\lVert x -
		y\rVert^2_2 \qquad \forall x,y\in\domain\mathcal T.
	\]

	If two operators \(\mathcal T\) and \(\mathcal S\) are monotone or maximal monotone (and 
	\(\domain\mathcal T\cap\domain\mathcal S \neq \emptyset \)), then so is \(\mathcal T + \mathcal S\). If in addition \(\mathcal T\) is coercive
	with parameter \(m\) and \(\mathcal S\) with parameter \(\hat{m}\), then \(\mathcal S + \mathcal T\) is coercive 
	(strongly monotone) with parameter \(m+\hat{m}\). For \(\alpha>0\), \(\alpha\mathcal T\) is coercive 
	with parameter \(\alpha m\).
\end{definition}
\end{document}
