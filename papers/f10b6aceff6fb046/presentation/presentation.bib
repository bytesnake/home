@book{naumann_art_diff,
author = {Naumann, Uwe},
title = {The Art of Differentiating Computer Programs},
publisher = {Society for Industrial and Applied Mathematics},
year = {2011},
doi = {10.1137/1.9781611972078},
address = {},
edition   = {},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611972078},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611972078}
}

@online{diffcg,
author = {Jan HÃ¼ckelheim},
title = {Testing and Verification of a Differentiated CG},
url = {https://www.autodiff.org/Docs/euroad/18th%20EuroAd%20Workshop%20-%20Jan%20Hueckelheim%20-%20Testing%20and%20verification%20of%20a%20differentiated%20CG%20solver.pdf},
organization = {Argonne National Laboratory, Queen Mary University London},
date = {2015-11-30},
urldate = {2022-03-27}
}

@article{tesselation,
  author    = {Giacomo Parigi and
               Marco Piastra},
  title     = {Gradient of the Objective Function for an Anisotropic Centroidal Voronoi
               Tessellation {(CVT)} - {A} revised, detailed derivation},
  journal   = {CoRR},
  volume    = {abs/1408.5622},
  year      = {2014},
  url       = {http://arxiv.org/abs/1408.5622},
  eprinttype = {arXiv},
  eprint    = {1408.5622},
  timestamp = {Mon, 13 Aug 2018 16:47:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ParigiP14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@BOOK{griewank,
       author = "Andreas Griewank and Andrea Walther",
       title = "Evaluating Derivatives: {P}rinciples and Techniques of Algorithmic Differentiation",
       publisher = "SIAM",
       series = "Other Titles in Applied Mathematics",
       edition = "2nd",
       address = "Philadelphia, PA",
       isbn = "978--0--898716--59--7",
       ad_theotech = "General, Introduction",
       year = "2008",
       url = "http://bookstore.siam.org/ot105/",
       abstract = "Algorithmic, or automatic, differentiation (AD) is a growing area of theoretical
         research and software development concerned with the accurate and efficient evaluation of
         derivatives for function evaluations given as computer programs. The resulting derivative values are
         useful for all scientific computations that are based on linear, quadratic, or higher order
         approximations to nonlinear scalar or vector functions.\par AD has been applied in particular
         to optimization, parameter identification, nonlinear equation solving, the numerical integration of
         differential equations, and combinations of these. Apart from quantifying sensitivities numerically,
         AD also yields structural dependence information, such as the sparsity pattern and generic rank of
         Jacobian matrices. The field opens up an exciting opportunity to develop new algorithms that reflect
         the true cost of accurate derivatives and to use them for improvements in speed and
         reliability.\par This second edition has been updated and expanded to cover recent developments
         in applications and theory, including an elegant NP completeness argument by Uwe Naumann and a brief
         introduction to scarcity, a generalization of sparsity. There is also added material on
         checkpointing and iterative differentiation. To improve readability the more detailed analysis of
         memory and complexity bounds has been relegated to separate, optional chapters.The book consists of
         three parts: a stand-alone introduction to the fundamentals of AD and its software; a thorough
         treatment of methods for sparse problems; and final chapters on program-reversal schedules, higher
         derivatives, nonsmooth problems and iterative processes. Each of the 15 chapters concludes with
         examples and exercises.",
       number = "105"
}

@inproceedings{enzymeNeurips,
  author = {Moses, William and Churavy, Valentin},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M. F. and Lin, H.},
  pages = {12472--12485},
  publisher = {Curran Associates, Inc.},
  title = {Instead of Rewriting Foreign Code for Machine Learning, Automatically Synthesize Fast Gradients},
  url = {https://proceedings.neurips.cc/paper/2020/file/9332c513ef44b682e9347822c2e457ac-Paper.pdf},
  volume = {33},
  year = {2020},
  award = {Spotlight Presentation},
  shortname = {NeurIPS '20},
  pdf = {https://proceedings.neurips.cc/paper/2020/file/9332c513ef44b682e9347822c2e457ac-Paper.pdf},
  hackernews = {https://news.ycombinator.com/item?id=26012289},
  reddit = {https://www.reddit.com/r/cpp/comments/j7fb4a/enzyme_highperformance_automatic_differentiation},
  papertype = {conference},
  tex = {https://github.com/wsmoses/Paper-EnzymeNeurips20},
  overleaf = {https://www.overleaf.com/project/5ec2b7bc4e59f40001a9be13}
}

@article{Cai_2022,
	doi = {10.1111/cgf.14592},
	url = {https://doi.org/10.1111%2Fcgf.14592},
	year = 2022,
	month = {jul},
	publisher = {Wiley},
	volume = {41},
	number = {4},
	pages = {129--138},
	author = {G. Cai and K. Yan and Z. Dong and I. Gkioulekas and S. Zhao},
	title = {Physics-Based Inverse Rendering using Combined Implicit and Explicit Geometries},
	journal = {Computer Graphics Forum}
}
